{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"workload.log\"\n",
    "rq_stats_file = \"range_queries.csv\"\n",
    "\n",
    "# CPU & IO Stats File\n",
    "cpu_iostat_file = \"cpu_iostat.txt\"\n",
    "cpu_top_file = \"cpu_top.txt\"\n",
    "io_iostat_file = \"io_iostat.txt\"\n",
    "\n",
    "CWD = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_epochs_data(filename, time_stats=False):\n",
    "    \"\"\"Read `workload.log` file and return one epoch data\"\"\"\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        epoch_data = []\n",
    "        grabbing_data = False\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"=====================\"):\n",
    "                if grabbing_data:\n",
    "                    yield epoch_data\n",
    "                    epoch_data = []\n",
    "                    grabbing_data = False\n",
    "            elif grabbing_data:\n",
    "                epoch_data.append(line)\n",
    "            else:\n",
    "                grabbing_data = True\n",
    "                epoch_data.append(line)\n",
    "        if time_stats:\n",
    "            yield epoch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_column_family(lines):\n",
    "    \"\"\"Extract Column Family information from one epoch data\"\"\"\n",
    "    \n",
    "    # Initialize variables to store column family data\n",
    "    column_family_data = {\"Levels\": []}\n",
    "    sst_files = {}\n",
    "    i = 0\n",
    "\n",
    "    # Process each line\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        # Check if the line contains column family data\n",
    "        if line.startswith(\"Column Family Name\"):\n",
    "            key_val = line.split(',')\n",
    "            column_family_data[\"Column Family Name\"] = key_val[0].split(':')[1].strip().strip(',')\n",
    "            column_family_data[\"Size\"] = int(key_val[1].split(':')[1].strip().strip(',').strip(' bytes'))\n",
    "            column_family_data[\"Files Count\"] = int(key_val[2].split(':')[1].strip().strip(','))\n",
    "            column_family_data[\"Entries Count\"] = int(key_val[3].split(':')[1].strip().strip(','))\n",
    "            column_family_data[\"Invalid Entries Count\"] = int(key_val[4].split(':')[1].strip().strip(','))\n",
    "        if \"Level:\" in line:\n",
    "            key_val = line.strip().split(',')\n",
    "            level = int(key_val[0].split(\":\")[1].strip().strip(','))\n",
    "            level_size = int(key_val[1].split(':')[1].strip().strip(',').strip(' bytes'))\n",
    "            level_files_count = int(key_val[2].split(':')[1].strip().strip(','))\n",
    "\n",
    "            key_val_sst_files = lines[i+1].split('],')[:-1]\n",
    "            sst_files = []\n",
    "            \n",
    "            for sst_file_string in key_val_sst_files:\n",
    "                # Extract SST file details\n",
    "                file_number = int(sst_file_string.split(\":\")[0].split(\"[#\")[1].strip())\n",
    "                file_details = sst_file_string.split(\":\")[1].strip().split()\n",
    "                file_size = int(file_details[0].strip())\n",
    "                smallest_key = int(file_details[1].strip(',').strip('('))\n",
    "                largest_key = int(file_details[2].strip(')'))\n",
    "                entries_count = int(file_details[3].strip(']'))\n",
    "\n",
    "                sst_files.append({\n",
    "                    \"FNo\": file_number,\n",
    "                    \"FileSize\": file_size,\n",
    "                    \"SmallesKey\": smallest_key,\n",
    "                    \"LargestKey\": largest_key,\n",
    "                    \"EntriesCount\": entries_count\n",
    "                })\n",
    "            \n",
    "            if len(sst_files) > 0:\n",
    "                column_family_data[\"Levels\"].append({\n",
    "                    \"Level\": level,\n",
    "                    \"LevelSize\": level_size,\n",
    "                    \"LevelFilesCount\": level_files_count,\n",
    "                    \"SSTFiles\": sst_files\n",
    "                })\n",
    "            i += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return column_family_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_total_write_bytes(one_epoch):\n",
    "    \"\"\"\n",
    "    rocksdb.compact.read.bytes\n",
    "    rocksdb.compact.write.bytes\n",
    "    rocksdb.flush.write.bytes\n",
    "    \"\"\"\n",
    "    read_bytes = 0\n",
    "    write_bytes = 0\n",
    "\n",
    "    for line in one_epoch:\n",
    "        if line.startswith(\"rocksdb.compact.read.bytes\"):\n",
    "            read_bytes += int(line.split(':')[1])\n",
    "        elif line.startswith('rocksdb.compact.write.bytes') or line.startswith('rocksdb.flush.write.bytes'):\n",
    "            write_bytes += int(line.split(':')[1])\n",
    "    \n",
    "    return read_bytes, write_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_times(one_epoch):\n",
    "    \"\"\"\n",
    "    Workload Execution Time: \n",
    "    Operations Execution Time: \n",
    "    All Inserts Time: \n",
    "    All Updates Time: \n",
    "    All Range Queries Time: \n",
    "    \"\"\"\n",
    "    workload_execution_time = 0\n",
    "    operation_time = 0\n",
    "    inserts_time = 0\n",
    "    updates_time = 0\n",
    "    range_queries_time = 0\n",
    "\n",
    "    for line in one_epoch:\n",
    "        if line.startswith(\"Workload Execution Time:\"):\n",
    "            workload_execution_time = int(line.split(':')[1].strip())\n",
    "        if line.startswith(\"Operations Execution Time\"):\n",
    "            operation_time = int(line.split(':')[1].strip())\n",
    "        if line.startswith(\"All Inserts Time\"):\n",
    "            inserts_time = int(line.split(':')[1].strip())\n",
    "        if line.startswith(\"All Updates Time\"):\n",
    "            updates_time = int(line.split(':')[1].strip())\n",
    "        if line.startswith(\"All Range Queries Time\"):\n",
    "            range_queries_time = int(line.split(':')[1].strip())\n",
    "\n",
    "    return [workload_execution_time, operation_time, inserts_time, updates_time, range_queries_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find compaction debt, write amplification and entries per file\n",
    "\n",
    "def compaction_debt(cfd_data):\n",
    "    # Iterate through levels, summing up entries count for levels except the last one\n",
    "    compaction_debt = 0\n",
    "\n",
    "    sorted_levels = sorted(cfd_data['Levels'], key=lambda x: x['Level'])\n",
    "    \n",
    "    for level in sorted_levels[:-1]:\n",
    "        for sst_file in level['SSTFiles']:\n",
    "            compaction_debt += sst_file['EntriesCount']\n",
    "\n",
    "    return compaction_debt\n",
    "\n",
    "def write_amplification_debt(cfd_data):\n",
    "    entries_list = list()\n",
    "\n",
    "    sorted_levels = sorted(cfd_data['Levels'], key=lambda x: x['Level'])\n",
    "\n",
    "    for level in sorted_levels[:-1]:\n",
    "        for sst_file in level[\"SSTFiles\"]:\n",
    "            entries_list.append(sst_file['EntriesCount'])\n",
    "    \n",
    "    return sum([entries * (len(entries_list) - index + 1) for index, entries in enumerate(entries_list, 1)])\n",
    "\n",
    "def avg_entries_per_SST_file(cfd_data):\n",
    "    total_entries = 0\n",
    "    total_sst_files = 0\n",
    "\n",
    "    # Iterate through each level\n",
    "    for level in cfd_data['Levels']:\n",
    "        # Iterate through SST files in each level\n",
    "        for sst_file in level['SSTFiles']:\n",
    "            total_entries += sst_file['EntriesCount']\n",
    "            # total_sst_files += 1\n",
    "    \n",
    "    return total_entries / cfd_data[\"Files Count\"]\n",
    "    # return total_entries / total_sst_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rectangle_group):\n",
    "    for rect in rectangle_group:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f\"{height}\",\n",
    "                xy = (rect.get_x() + rect.get_width() / 2, height),\n",
    "                ha='center', color = 'grey', rotation=90, xytext=(0,5), textcoords=\"offset points\")\n",
    "\n",
    "def convert_ns_to_sec(val):\n",
    "    return val / (10**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory Not Found!!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     22\u001b[0m rqdc_dir_name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minserts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m U \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m S \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrange\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Y \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselectivity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msizeRatio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rq 1 E \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentrySize\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m B \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentriesPerPage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlb \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowerBound\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ub \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupperBound\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists((os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CWD, vanilla_dir_name))) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m     29\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CWD, rqdc_dir_name)\n\u001b[1;32m     30\u001b[0m ):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory Not Found!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     34\u001b[0m vanilla_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory Not Found!!!"
     ]
    }
   ],
   "source": [
    "plot_for = [\n",
    "    {\n",
    "        \"inserts\": 1000000,\n",
    "        \"updates\": 250000,\n",
    "        \"range\": 100,\n",
    "        \"selectivity\": 0.1,\n",
    "        \"sizeRatio\": 6,\n",
    "        \"entrySize\": 32,\n",
    "        \"entriesPerPage\": 128,\n",
    "        \"lowerBound\": 0.12,\n",
    "        \"upperBound\": 2,\n",
    "    },\n",
    "]\n",
    "\n",
    "FIG_SIZE = (12, 10)\n",
    "\n",
    "for exp in plot_for:\n",
    "    vanilla_dir_name = (\n",
    "        f\"I {exp['inserts']} U {exp['updates']} S {exp['range']} Y {exp['selectivity']} \"\n",
    "        f\"T {exp['sizeRatio']} rq 0 E {exp['entrySize']} B {exp['entriesPerPage']}\"\n",
    "    )\n",
    "    rqdc_dir_name = (\n",
    "        f\"I {exp['inserts']} U {exp['updates']} S {exp['range']} Y {exp['selectivity']} \"\n",
    "        f\"T {exp['sizeRatio']} rq 1 E {exp['entrySize']} B {exp['entriesPerPage']} \"\n",
    "        f\"lb {exp['lowerBound']} ub {exp['upperBound']}\"\n",
    "    )\n",
    "\n",
    "    if not os.path.exists((os.path.join(CWD, vanilla_dir_name))) or not os.path.exists(\n",
    "        os.path.join(CWD, rqdc_dir_name)\n",
    "    ):\n",
    "        raise FileNotFoundError(\"Directory Not Found!!!\")\n",
    "\n",
    "    first = True\n",
    "    vanilla_stats = list()\n",
    "    rqdc_stats = list()\n",
    "\n",
    "    vanilla_rq_stats = None\n",
    "    rqdc_rq_stats = None\n",
    "\n",
    "    for one_epoch in read_epochs_data(os.path.join(CWD, vanilla_dir_name, log_file)):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            cf_data = extract_column_family(one_epoch)\n",
    "            read_bytes, write_bytes = extract_total_write_bytes(one_epoch)\n",
    "            one_epoch_cd = compaction_debt(cf_data)\n",
    "            one_epoch_wa = write_amplification_debt(cf_data)\n",
    "            one_epoch_epf = avg_entries_per_SST_file(cf_data)\n",
    "\n",
    "            vanilla_stats.append(\n",
    "                {\n",
    "                    \"CompactionDebt\": one_epoch_cd,\n",
    "                    \"WriteAmpDebt\": one_epoch_wa,\n",
    "                    \"AvgEntriesPerSST\": one_epoch_epf,\n",
    "                    \"FilesCount\": cf_data[\"Files Count\"],\n",
    "                    \"DBSize\": cf_data[\"Size\"],\n",
    "                    \"TotalEntries\": cf_data[\"Entries Count\"],\n",
    "                    \"Invalid Entries\": cf_data[\"Invalid Entries Count\"],\n",
    "                    \"TotalReadBytes\": read_bytes,\n",
    "                    \"TotalWriteBytes\": write_bytes,\n",
    "                }\n",
    "            )\n",
    "    vanilla_rq_stats = pd.read_csv(os.path.join(CWD, vanilla_dir_name, rq_stats_file))\n",
    "    vanilla_rq_stats = vanilla_rq_stats.applymap(\n",
    "        lambda x: x.strip(\" \") if isinstance(x, str) else x\n",
    "    )\n",
    "    vanilla_rq_stats.columns = vanilla_rq_stats.columns.str.strip()\n",
    "\n",
    "    first = True\n",
    "\n",
    "    for one_epoch in read_epochs_data(os.path.join(CWD, rqdc_dir_name, log_file)):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            cf_data = extract_column_family(one_epoch)\n",
    "            read_bytes, write_bytes = extract_total_write_bytes(one_epoch)\n",
    "            one_epoch_cd = compaction_debt(cf_data)\n",
    "            one_epoch_wa = write_amplification_debt(cf_data)\n",
    "            one_epoch_epf = avg_entries_per_SST_file(cf_data)\n",
    "\n",
    "            rqdc_stats.append(\n",
    "                {\n",
    "                    \"CompactionDebt\": one_epoch_cd,\n",
    "                    \"WriteAmpDebt\": one_epoch_wa,\n",
    "                    \"AvgEntriesPerSST\": one_epoch_epf,\n",
    "                    \"FilesCount\": cf_data[\"Files Count\"],\n",
    "                    \"DBSize\": cf_data[\"Size\"],\n",
    "                    \"TotalEntries\": cf_data[\"Entries Count\"],\n",
    "                    \"Invalid Entries\": cf_data[\"Invalid Entries Count\"],\n",
    "                    \"TotalReadBytes\": read_bytes,\n",
    "                    \"TotalWriteBytes\": write_bytes,\n",
    "                }\n",
    "            )\n",
    "    rqdc_rq_stats = pd.read_csv(os.path.join(CWD, rqdc_dir_name, rq_stats_file))\n",
    "    rqdc_rq_stats = rqdc_rq_stats.applymap(\n",
    "        lambda x: x.strip(\" \") if isinstance(x, str) else x\n",
    "    )\n",
    "    rqdc_rq_stats.columns = rqdc_rq_stats.columns.str.strip()\n",
    "\n",
    "    x_tick_labels = [\n",
    "        \"inserts\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"updates & RQ\",\n",
    "        \"inserts\",\n",
    "    ]\n",
    "\n",
    "    # ============================================================================= #\n",
    "    #                    COMPACTION DEBT, WRITE AMP DEBT & DB SIZE                  #\n",
    "    # ============================================================================= #\n",
    "\n",
    "    width = 0.2\n",
    "    num_epochs = 12\n",
    "\n",
    "    x_compaction_dbt_van = [x - 0.3 for x in range(num_epochs)]\n",
    "    x_compaction_dbt_rqdc = [x - 0.1 for x in range(num_epochs)]\n",
    "    x_write_amp_dbt_van = [x + 0.1 for x in range(num_epochs)]\n",
    "    x_write_amp_dbt_rqdc = [x + 0.3 for x in range(num_epochs)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    rect1 = ax.bar(\n",
    "        x_compaction_dbt_van,\n",
    "        [stat[\"CompactionDebt\"] for stat in vanilla_stats],\n",
    "        width,\n",
    "        label=\"Compaction Debt (Vanilla)\",\n",
    "        color=\"maroon\",\n",
    "    )\n",
    "    rect2 = ax.bar(\n",
    "        x_compaction_dbt_rqdc,\n",
    "        [stat[\"CompactionDebt\"] for stat in rqdc_stats],\n",
    "        width,\n",
    "        label=\"Compaction Debt (RQDC)\",\n",
    "        color=\"olive\",\n",
    "    )\n",
    "    rect3 = ax2.bar(\n",
    "        x_write_amp_dbt_van,\n",
    "        [stat[\"WriteAmpDebt\"] for stat in vanilla_stats],\n",
    "        width,\n",
    "        label=(\"Write Amp Debt (Vanilla)\"),\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    rect4 = ax2.bar(\n",
    "        x_write_amp_dbt_rqdc,\n",
    "        [stat[\"WriteAmpDebt\"] for stat in rqdc_stats],\n",
    "        width,\n",
    "        label=\"Write Amp Debt (RQDC)\",\n",
    "        color=\"cornflowerblue\",\n",
    "    )\n",
    "    point1 = ax2.plot(\n",
    "        range(12),\n",
    "        [stat[\"DBSize\"] for stat in vanilla_stats],\n",
    "        label=\"DB Size (Vanilla)\",\n",
    "        color=\"red\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    point2 = ax2.plot(\n",
    "        range(12),\n",
    "        [stat[\"DBSize\"] for stat in rqdc_stats],\n",
    "        label=\"DB Size (RQDC)\",\n",
    "        color=\"olivedrab\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(range(num_epochs))\n",
    "    ax.set_xticklabels(\n",
    "        x_tick_labels, rotation=60\n",
    "    )  # [f\"{num}\" for num in range(1, num_epochs + 1)])\n",
    "\n",
    "    ax.set_title(\n",
    "        (\n",
    "            f'Inserts {exp[\"inserts\"]}, Updates {exp[\"updates\"]}, Range Queries Count {exp[\"range\"]}, Selectivity {exp[\"selectivity\"]}'\n",
    "            f'\\nSize Ratio {exp[\"sizeRatio\"]}, Entry Size {exp[\"entrySize\"]}, Entries Per Page {exp[\"entriesPerPage\"]}, lower bound {exp[\"lowerBound\"]}, upper bound {exp[\"upperBound\"]}'\n",
    "        )\n",
    "    )\n",
    "    ax.set_ylabel(\"Compaction Debt (Bytes)\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax2.set_ylabel(\"Write Amp Debt (Bytes)\")\n",
    "    ax2.legend()\n",
    "\n",
    "    for recta, rectb in zip(rect1, rect2):\n",
    "        heighta = recta.get_height()\n",
    "        heightb = rectb.get_height()\n",
    "        ax.annotate(f\"{((heighta - heightb)/heighta):.2f}\",\n",
    "                xy = (rectb.get_x() + rectb.get_width() / 2, heightb),\n",
    "                ha='center', color = 'black', rotation=90,\n",
    "                xytext=(0, 10), textcoords=\"offset points\")\n",
    "\n",
    "    for recta, rectb in zip(rect3, rect4):\n",
    "        heighta = recta.get_height()\n",
    "        heightb = rectb.get_height()\n",
    "        ax2.annotate(f\"{((heighta - heightb)/heighta):.2f}\",\n",
    "                xy = (rectb.get_x() + rectb.get_width() / 2, heightb),\n",
    "                ha='center', color = 'black', rotation=90,\n",
    "                xytext=(0, 10), textcoords=\"offset points\")\n",
    "\n",
    "    i = 0\n",
    "    for p1, p2 in zip([stat[\"DBSize\"] for stat in vanilla_stats], [stat[\"DBSize\"] for stat in rqdc_stats]):\n",
    "        ax2.annotate(f\"{((p1 - p2)/p2):.2f}\",\n",
    "                xy = (i, p2),\n",
    "                ha='center', color = 'black',\n",
    "                xytext=(0, -10), textcoords=\"offset points\")\n",
    "        i += 1\n",
    "\n",
    "    plt.savefig(\"debts.eps\", format=\"eps\", bbox_inches=\"tight\", dpi=1200)\n",
    "    plt.show()\n",
    "\n",
    "    # ============================================================================= #\n",
    "    #                    COMPACTION DEBT, WRITE AMP DEBT & DB SIZE                  #\n",
    "    # ============================================================================= #\n",
    "\n",
    "    # width = 0.2\n",
    "    # num_epochs = 12\n",
    "\n",
    "    # x_compaction_dbt_van = [x - 0.1 for x in range(num_epochs)]\n",
    "    # x_compaction_dbt_rqdc = [x + 0.1 for x in range(num_epochs)]\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "\n",
    "    # ax2 = ax.twinx()\n",
    "\n",
    "    # ax.bar(x_compaction_dbt_van, [stat[\"CompactionDebt\"] for stat in vanilla_stats], width, label=\"Compaction Debt (Vanilla)\", color=\"maroon\")\n",
    "    # ax.bar(x_compaction_dbt_rqdc, [stat[\"CompactionDebt\"] for stat in rqdc_stats], width, label=\"Compaction Debt (RQDC)\", color='olive')\n",
    "    # ax2.plot(range(12), [stat[\"DBSize\"] for stat in vanilla_stats], label=\"DB Size (Vanilla)\", color=\"red\", marker='o')\n",
    "    # ax2.plot(range(12), [stat[\"DBSize\"] for stat in rqdc_stats], label=\"DB Size (RQDC)\", color=\"olivedrab\", marker='o')\n",
    "\n",
    "    # ax.set_xticks(range(num_epochs))\n",
    "    # ax.set_xticklabels(x_tick_labels, rotation=45)  # [f\"{num}\" for num in range(1, num_epochs + 1)])\n",
    "\n",
    "    # ax.set_title((f'Inserts {exp[\"inserts\"]}, Updates {exp[\"updates\"]}, Range Queries Count {exp[\"range\"]}, Selectivity {exp[\"selectivity\"]}'\n",
    "    #               f'\\nSize Ratio {exp[\"sizeRatio\"]}, Entry Size {exp[\"entrySize\"]}, Entries Per Page {exp[\"entriesPerPage\"]}, lower bound {exp[\"lowerBound\"]}, upper bound {exp[\"upperBound\"]}'))\n",
    "    # ax.set_ylabel(\"Compaction Debt (Bytes)\")\n",
    "    # ax.set_xlabel(\"Epoch\")\n",
    "    # ax.legend()\n",
    "\n",
    "    # ax2.set_ylabel(\"Database Size (Bytes)\")\n",
    "    # ax2.set_ylim(0, 48*(10**6))\n",
    "    # ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # ============================================================================= #\n",
    "    #                          VALID / INVALID ENTRIES COUNT                        #\n",
    "    # ============================================================================= #\n",
    "\n",
    "    width = 0.2\n",
    "    num_epochs = 12\n",
    "\n",
    "    x_total_entries_van = [x - 0.3 for x in range(num_epochs)]\n",
    "    x_total_entries_rqdc = [x - 0.1 for x in range(num_epochs)]\n",
    "    x_total_invalid_entries_van = [x + 0.1 for x in range(num_epochs)]\n",
    "    x_total_invalid_entries_rqdc = [x + 0.3 for x in range(num_epochs)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "\n",
    "    rect1 = ax.bar(\n",
    "        x_total_entries_van,\n",
    "        [stat[\"TotalEntries\"] for stat in vanilla_stats],\n",
    "        width,\n",
    "        label=\"Total Entries (Vanilla)\",\n",
    "        color=\"maroon\",\n",
    "    )\n",
    "    rect2 = ax.bar(\n",
    "        x_total_entries_rqdc,\n",
    "        [stat[\"TotalEntries\"] for stat in rqdc_stats],\n",
    "        width,\n",
    "        label=\"Total Entries (RQDC)\",\n",
    "        color=\"olive\",\n",
    "    )\n",
    "    rect3 = ax.bar(\n",
    "        x_total_invalid_entries_van,\n",
    "        [stat[\"Invalid Entries\"] for stat in vanilla_stats],\n",
    "        width,\n",
    "        label=\"Invalid Entries (Vanilla)\",\n",
    "        color=\"red\",\n",
    "    )\n",
    "    rect4 = ax.bar(\n",
    "        x_total_invalid_entries_rqdc,\n",
    "        [stat[\"Invalid Entries\"] for stat in rqdc_stats],\n",
    "        width,\n",
    "        label=\"Invalid Entries (RQDC)\",\n",
    "        color=\"orange\",\n",
    "    )\n",
    "\n",
    "    ax.axhline(y=exp[\"inserts\"], linestyle=\"--\", label=\"Total Unique Inserts\")\n",
    "\n",
    "    ax.set_xticks(range(num_epochs))\n",
    "    ax.set_xticklabels(\n",
    "        x_tick_labels, rotation=60\n",
    "    )  # [f\"{num}\" for num in range(1, num_epochs + 1)])\n",
    "\n",
    "    ax.set_title(\n",
    "        (\n",
    "            f'Inserts {exp[\"inserts\"]}, Updates {exp[\"updates\"]}, Range Queries Count {exp[\"range\"]}, Selectivity {exp[\"selectivity\"]}'\n",
    "            f'\\nSize Ratio {exp[\"sizeRatio\"]}, Entry Size {exp[\"entrySize\"]}, Entries Per Page {exp[\"entriesPerPage\"]}, lower bound {exp[\"lowerBound\"]}, upper bound {exp[\"upperBound\"]}'\n",
    "        )\n",
    "    )\n",
    "    ax.set_ylabel(\"Total Valid / Invalid Entries (Count)\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylim(0, 15 * (10**5))\n",
    "    ax.legend()\n",
    "\n",
    "    autolabel(rect1)\n",
    "    autolabel(rect2)\n",
    "    autolabel(rect3)\n",
    "    autolabel(rect4)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # ============================================================================= #\n",
    "    #                  RANGE QUERIES Time + Entries Count                           #\n",
    "    # ============================================================================= #\n",
    "\n",
    "    width = 0.2\n",
    "    # x_useful_entries = [x-0.1 for x in range(exp['range'])]\n",
    "    # x_unuseful_entries = [x+0.1 for x in range(exp['range'])]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    ax.plot(\n",
    "        range(exp[\"range\"]),\n",
    "        vanilla_rq_stats[\"RQ Total Time\"].apply(convert_ns_to_sec),\n",
    "        label=\"RQ's Time (Vanilla)\",\n",
    "        color=\"maroon\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        range(exp[\"range\"]),\n",
    "        rqdc_rq_stats[\"RQ Total Time\"].apply(convert_ns_to_sec),\n",
    "        label=\"RQ's Time (RQDC)\",\n",
    "        color=\"limegreen\",\n",
    "    )\n",
    "\n",
    "    # ax2.bar(x_useful_entries, rqdc_rq_stats[\"uEntries Count Written Back\"], width, label=\"Useful Entries\")\n",
    "    # ax2.bar(x_unuseful_entries, rqdc_rq_stats[\"unEntries Count Written Back\"], width, label=\"Unuseful Entries\")\n",
    "\n",
    "    ax2.plot(\n",
    "        range(exp[\"range\"]),\n",
    "        vanilla_rq_stats[\"Total Entries Read\"],\n",
    "        label=\"Read Entries (Vanilla)\",\n",
    "    )\n",
    "    ax2.plot(\n",
    "        range(exp[\"range\"]),\n",
    "        rqdc_rq_stats[\"Total Entries Read\"],\n",
    "        label=\"Read Entries (RQDC)\",\n",
    "        color=\"orange\",\n",
    "    )\n",
    "\n",
    "    # ax.set_xticks(range(exp['range']))\n",
    "    # ax.set_xticklabels(range(1, exp['range']+1), rotation=90)\n",
    "\n",
    "    ax.set_title(\n",
    "        (\n",
    "            f'Inserts {exp[\"inserts\"]}, Updates {exp[\"updates\"]}, Range Queries Count {exp[\"range\"]}, Selectivity {exp[\"selectivity\"]}'\n",
    "            f'\\nSize Ratio {exp[\"sizeRatio\"]}, Entry Size {exp[\"entrySize\"]}, Entries Per Page {exp[\"entriesPerPage\"]}, lower bound {exp[\"lowerBound\"]}, upper bound {exp[\"upperBound\"]}'\n",
    "        )\n",
    "    )\n",
    "    ax.set_ylabel(\"Range Queries Time (Seconds)\")\n",
    "    ax.set_xlabel(\"Range Query Number\")\n",
    "    ax.set_ylim(0, 0.5)\n",
    "\n",
    "    ax2.set_ylim(1, 150000)\n",
    "    ax2.set_ylabel(\"Total Entries Read for Range Query (Count)\")\n",
    "    ax.legend()\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # ============================================================================= #\n",
    "    #                              RQ Useful + Unuseful entries                     #\n",
    "    # ============================================================================= #\n",
    "\n",
    "    # width = 0.2\n",
    "    # x_useful_entries = [x-0.1 for x in range(exp['range'])]\n",
    "    # x_unuseful_entries = [x+0.1 for x in range(exp['range'])]\n",
    "    bottom_unuseful = rqdc_rq_stats[\"uEntries Count Written Back\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    # ax.plot(range(exp['range']), vanilla_rq_stats[\"RQ Total Time\"].apply(convert_ns_to_sec), label=\"RQ's Time (Vanilla)\", color=\"limegreen\")\n",
    "    # ax.plot(range(exp['range']), rqdc_rq_stats[\"RQ Total Time\"].apply(convert_ns_to_sec), label=\"RQ's Time (RQDC)\", color=\"maroon\")\n",
    "\n",
    "    ax.bar(\n",
    "        range(exp[\"range\"]),\n",
    "        rqdc_rq_stats[\"uEntries Count Written Back\"],\n",
    "        label=\"Useful Entries\",\n",
    "    )\n",
    "    ax.bar(\n",
    "        range(exp[\"range\"]),\n",
    "        rqdc_rq_stats[\"unEntries Count Written Back\"],\n",
    "        bottom=bottom_unuseful,\n",
    "        label=\"Unuseful Entries\",\n",
    "        color=\"indianred\"\n",
    "    )\n",
    "    ax.plot(\n",
    "        range(exp[\"range\"]),\n",
    "        rqdc_rq_stats[\"Total Entries Read\"],\n",
    "        label=\"Read Entries (RQDC)\",\n",
    "        color=\"maroon\",\n",
    "    )\n",
    "\n",
    "    # ax2.plot(range(exp['range']), vanilla_rq_stats[\"Total Entries Read\"], label=\"Read Entries (Vanilla)\")\n",
    "    # ax2.plot(range(exp['range']), rqdc_rq_stats[\"Total Entries Read\"], label=\"Read Entries (RQDC)\", color=\"orange\")\n",
    "\n",
    "    # ax.set_xticks(range(exp['range']))\n",
    "    # ax.set_xticklabels(range(1, exp['range']+1), rotation=90)\n",
    "\n",
    "    ax.set_title(\n",
    "        (\n",
    "            f'Inserts {exp[\"inserts\"]}, Updates {exp[\"updates\"]}, Range Queries Count {exp[\"range\"]}, Selectivity {exp[\"selectivity\"]}'\n",
    "            f'\\nSize Ratio {exp[\"sizeRatio\"]}, Entry Size {exp[\"entrySize\"]}, Entries Per Page {exp[\"entriesPerPage\"]}, lower bound {exp[\"lowerBound\"]}, upper bound {exp[\"upperBound\"]}'\n",
    "        )\n",
    "    )\n",
    "    ax.set_ylabel(\"Total Entries written back (Count)\")\n",
    "    ax.set_xlabel(\"Range Query Number\")\n",
    "\n",
    "    # ax2.set_ylim(1, 150000)\n",
    "    # ax2.set_ylabel(\"Total Entries Read for Range Query (Count)\")\n",
    "    ax.legend()\n",
    "    # ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # ============================================================================= #\n",
    "    #                           Number of SST File at diff epoch                    #\n",
    "    # ============================================================================= #\n",
    "\n",
    "    width = 0.2\n",
    "    num_epochs = 12\n",
    "\n",
    "    x_vanilla = [x - 0.1 for x in range(num_epochs)]\n",
    "    x_rqdc = [x + 0.1 for x in range(num_epochs)]\n",
    "\n",
    "    bottom_unuseful = rqdc_rq_stats[\"uEntries Count Written Back\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    ax.bar(\n",
    "        x_vanilla,\n",
    "        [stats[\"FilesCount\"] for stats in vanilla_stats],\n",
    "        width,\n",
    "        label=\"Files Count (Vanilla)\",\n",
    "    )\n",
    "    ax.bar(\n",
    "        x_rqdc,\n",
    "        [stats[\"FilesCount\"] for stats in rqdc_stats],\n",
    "        width,\n",
    "        label=\"Files Count (RQDC)\",\n",
    "    )\n",
    "\n",
    "    ax2.plot(\n",
    "        range(num_epochs),\n",
    "        [stats[\"AvgEntriesPerSST\"] for stats in vanilla_stats],\n",
    "        marker=\"o\",\n",
    "        color=\"maroon\",\n",
    "        label=\"Avg Entries per SST (Vanilla)\",\n",
    "    )\n",
    "    ax2.plot(\n",
    "        range(num_epochs),\n",
    "        [stats[\"AvgEntriesPerSST\"] for stats in rqdc_stats],\n",
    "        marker=\"o\",\n",
    "        color=\"limegreen\",\n",
    "        label=\"Avg Entries per SST (RQDC)\",\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(range(num_epochs))\n",
    "    ax.set_xticklabels(\n",
    "        x_tick_labels, rotation=45\n",
    "    )  # [f\"{num}\" for num in range(1, num_epochs + 1)])\n",
    "\n",
    "    ax.set_title(\n",
    "        (\n",
    "            f'Inserts {exp[\"inserts\"]}, Updates {exp[\"updates\"]}, Range Queries Count {exp[\"range\"]}, Selectivity {exp[\"selectivity\"]}'\n",
    "            f'\\nSize Ratio {exp[\"sizeRatio\"]}, Entry Size {exp[\"entrySize\"]}, Entries Per Page {exp[\"entriesPerPage\"]}, lower bound {exp[\"lowerBound\"]}, upper bound {exp[\"upperBound\"]}'\n",
    "        )\n",
    "    )\n",
    "    ax.set_ylabel(\"Total Number of SST Files (Count)\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    ax2.set_ylabel(\"Average Entries Per SST File\")\n",
    "    ax2.set_ylim(0, max([stats[\"AvgEntriesPerSST\"] for stats in rqdc_stats]) + 1000)\n",
    "\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # ============================================================================= #\n",
    "    #            Total Read Write Bytes over the Workload Execution                 #\n",
    "    # ============================================================================= #\n",
    "\n",
    "    width = 0.2\n",
    "    num_epochs = 12\n",
    "\n",
    "    x_compaction_dbt_van = [x - 0.3 for x in range(num_epochs)]\n",
    "    x_compaction_dbt_rqdc = [x - 0.1 for x in range(num_epochs)]\n",
    "    x_write_amp_dbt_van = [x + 0.1 for x in range(num_epochs)]\n",
    "    x_write_amp_dbt_rqdc = [x + 0.3 for x in range(num_epochs)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "\n",
    "    # ax2 = ax.twinx()\n",
    "\n",
    "    ax.bar(\n",
    "        x_compaction_dbt_van,\n",
    "        [stat[\"TotalReadBytes\"] for stat in vanilla_stats],\n",
    "        width,\n",
    "        label=\"Vanilla Read\",\n",
    "        color=\"maroon\",\n",
    "    )\n",
    "    ax.bar(\n",
    "        x_compaction_dbt_rqdc,\n",
    "        [stat[\"TotalReadBytes\"] for stat in rqdc_stats],\n",
    "        width,\n",
    "        label=\"RQDC Read\",\n",
    "        color=\"olive\",\n",
    "    )\n",
    "    ax.bar(\n",
    "        x_write_amp_dbt_van,\n",
    "        [stat[\"TotalWriteBytes\"] for stat in vanilla_stats],\n",
    "        width,\n",
    "        label=(\"Vanilla Writes\"),\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    ax.bar(\n",
    "        x_write_amp_dbt_rqdc,\n",
    "        [stat[\"TotalWriteBytes\"] for stat in rqdc_stats],\n",
    "        width,\n",
    "        label=\"RQDC Writes\",\n",
    "        color=\"cornflowerblue\",\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(range(num_epochs))\n",
    "    ax.set_xticklabels(\n",
    "        x_tick_labels, rotation=45\n",
    "    )  # [f\"{num}\" for num in range(1, num_epochs + 1)])\n",
    "\n",
    "    ax.set_title(\n",
    "        (\n",
    "            f'Inserts {exp[\"inserts\"]}, Updates {exp[\"updates\"]}, Range Queries Count {exp[\"range\"]}, Selectivity {exp[\"selectivity\"]}'\n",
    "            f'\\nSize Ratio {exp[\"sizeRatio\"]}, Entry Size {exp[\"entrySize\"]}, Entries Per Page {exp[\"entriesPerPage\"]}, lower bound {exp[\"lowerBound\"]}, upper bound {exp[\"upperBound\"]}'\n",
    "        )\n",
    "    )\n",
    "    ax.set_ylabel(\"Read / Write Bytes\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.legend()\n",
    "\n",
    "    # ax2.set_ylabel(\"Write Amp Debt (Bytes)\")\n",
    "    # ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
